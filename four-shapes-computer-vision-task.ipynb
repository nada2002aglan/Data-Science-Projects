{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7569,"sourceType":"datasetVersion","datasetId":4880},{"sourceId":7810158,"sourceType":"datasetVersion","datasetId":4574382}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nadaaglan/four-shapes-computer-vision-task?scriptVersionId=180244962\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"ae1d774f","execution":{"iopub.status.busy":"2024-03-10T19:23:35.292871Z","iopub.execute_input":"2024-03-10T19:23:35.293269Z","iopub.status.idle":"2024-03-10T19:23:35.299422Z","shell.execute_reply.started":"2024-03-10T19:23:35.293242Z","shell.execute_reply":"2024-03-10T19:23:35.298326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions\n\n- `imread`: Read an image from `img_path` and convert it to RGB\n- `imshow`: Display the given `img` (`figsize` is optional figure size)\n- `rgb2bin`: Convert the given RGB image `img_rgb` to binary\n- `find_best_contour`: Find and return the largest contour in the image","metadata":{"id":"e94e1676"}},{"cell_type":"code","source":"def imread(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\ndef imshow(img, figsize=(5, 5)):\n    plt.figure(figsize=figsize)\n    plt.imshow(img, cmap='gray')\n    plt.show()\n\ndef rgb2bin(img_rgb):\n    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n    t, img_bin = cv2.threshold(\n        img_gray, 0, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV\n    )\n    return img_bin\n\ndef find_best_contour(img_rgb):\n    img_bin = rgb2bin(img_rgb)\n    contours, h = cv2.findContours(\n        img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n    )\n    best_contour = max(contours, key=cv2.contourArea)\n    return best_contour\n\ndef draw_contours(img, contours, index=-1, color=(255, 0, 0), thickness=2):\n    img_copy = img.copy()\n    cv2.drawContours(img_copy, contours, index, color, thickness)\n    imshow(img_copy)","metadata":{"id":"13067030","execution":{"iopub.status.busy":"2024-03-10T19:23:38.487642Z","iopub.execute_input":"2024-03-10T19:23:38.488068Z","iopub.status.idle":"2024-03-10T19:23:38.50009Z","shell.execute_reply.started":"2024-03-10T19:23:38.488037Z","shell.execute_reply":"2024-03-10T19:23:38.498103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = imread('/kaggle/input/imagesss/triangle-hollow.png')\nimshow(img)","metadata":{"id":"f05a7101","outputId":"d0aa0579-63df-475d-8838-27ca6ddb8fc2","execution":{"iopub.status.busy":"2024-03-10T19:46:15.549325Z","iopub.execute_input":"2024-03-10T19:46:15.549801Z","iopub.status.idle":"2024-03-10T19:46:15.836995Z","shell.execute_reply.started":"2024-03-10T19:46:15.549757Z","shell.execute_reply":"2024-03-10T19:46:15.835712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_contour = find_best_contour(img)\ndraw_contours(img, best_contour)","metadata":{"id":"40842ccf","execution":{"iopub.status.busy":"2024-03-10T19:29:09.095095Z","iopub.execute_input":"2024-03-10T19:29:09.095519Z","iopub.status.idle":"2024-03-10T19:29:09.379871Z","shell.execute_reply.started":"2024-03-10T19:29:09.095487Z","shell.execute_reply":"2024-03-10T19:29:09.379057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chain code histogram\n\nWe loop through the best contour points to generate chain code like the following image. We find the chain code by calculating the difference in x (`dx`) and difference in y (`dy`) between each point and the next point.\n\n<img src=\"images/chain-codes-diagram.png\" alt=\"chian codes diagram\" width=\"400\"/>\n","metadata":{"id":"014ae5f5"}},{"cell_type":"code","source":"best_contour","metadata":{"id":"01ce10d4","execution":{"iopub.status.busy":"2024-03-10T19:29:36.576608Z","iopub.execute_input":"2024-03-10T19:29:36.57701Z","iopub.status.idle":"2024-03-10T19:29:36.591987Z","shell.execute_reply.started":"2024-03-10T19:29:36.57698Z","shell.execute_reply":"2024-03-10T19:29:36.590813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_contour.shape","metadata":{"id":"e98771a0","execution":{"iopub.status.busy":"2024-03-10T19:29:50.489197Z","iopub.execute_input":"2024-03-10T19:29:50.489574Z","iopub.status.idle":"2024-03-10T19:29:50.496875Z","shell.execute_reply.started":"2024-03-10T19:29:50.489547Z","shell.execute_reply":"2024-03-10T19:29:50.49533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_contour[0][0]","metadata":{"id":"3c3b4ae6","execution":{"iopub.status.busy":"2024-03-10T19:29:54.390821Z","iopub.execute_input":"2024-03-10T19:29:54.391231Z","iopub.status.idle":"2024-03-10T19:29:54.399413Z","shell.execute_reply.started":"2024-03-10T19:29:54.391202Z","shell.execute_reply":"2024-03-10T19:29:54.398071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1,y1=best_contour[0][0]\nx1,y1","metadata":{"id":"f28e037d","execution":{"iopub.status.busy":"2024-03-10T19:29:57.862467Z","iopub.execute_input":"2024-03-10T19:29:57.862843Z","iopub.status.idle":"2024-03-10T19:29:57.869234Z","shell.execute_reply.started":"2024-03-10T19:29:57.862815Z","shell.execute_reply":"2024-03-10T19:29:57.868257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x2,y2=best_contour[1][0]\nx2,y2","metadata":{"id":"5acb96bf","execution":{"iopub.status.busy":"2024-03-10T19:30:00.659808Z","iopub.execute_input":"2024-03-10T19:30:00.66019Z","iopub.status.idle":"2024-03-10T19:30:00.668879Z","shell.execute_reply.started":"2024-03-10T19:30:00.660163Z","shell.execute_reply":"2024-03-10T19:30:00.666346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x2-x1,y2-y1","metadata":{"id":"801f7ad4","execution":{"iopub.status.busy":"2024-03-10T19:30:03.601859Z","iopub.execute_input":"2024-03-10T19:30:03.602322Z","iopub.status.idle":"2024-03-10T19:30:03.609484Z","shell.execute_reply.started":"2024-03-10T19:30:03.602289Z","shell.execute_reply":"2024-03-10T19:30:03.608253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if x2-x1 == -1 and  y2-y1 == 1 :\n    code = 1\n    print(code)","metadata":{"id":"8fc828b3","execution":{"iopub.status.busy":"2024-03-10T19:30:06.472911Z","iopub.execute_input":"2024-03-10T19:30:06.473285Z","iopub.status.idle":"2024-03-10T19:30:06.479837Z","shell.execute_reply.started":"2024-03-10T19:30:06.473258Z","shell.execute_reply":"2024-03-10T19:30:06.478467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"code","metadata":{"id":"fd0b7369","execution":{"iopub.status.busy":"2024-03-10T19:30:13.13443Z","iopub.execute_input":"2024-03-10T19:30:13.135367Z","iopub.status.idle":"2024-03-10T19:30:13.142067Z","shell.execute_reply.started":"2024-03-10T19:30:13.135328Z","shell.execute_reply":"2024-03-10T19:30:13.140834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d={\n    (-1,1):1\n}","metadata":{"id":"5486d20a","execution":{"iopub.status.busy":"2024-03-10T19:30:18.727955Z","iopub.execute_input":"2024-03-10T19:30:18.728329Z","iopub.status.idle":"2024-03-10T19:30:18.733011Z","shell.execute_reply.started":"2024-03-10T19:30:18.728295Z","shell.execute_reply":"2024-03-10T19:30:18.731823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d[(x2-x1,y2-y1)]","metadata":{"id":"0a4f70f1","execution":{"iopub.status.busy":"2024-03-10T19:30:20.869693Z","iopub.execute_input":"2024-03-10T19:30:20.870104Z","iopub.status.idle":"2024-03-10T19:30:20.877652Z","shell.execute_reply.started":"2024-03-10T19:30:20.870075Z","shell.execute_reply":"2024-03-10T19:30:20.87658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a lookup table that maps between (`dx`, `dy`) and the chain code value according to the image above:\n- Each key in the table is (`dx`, `dy`)\n- The value is the chain code value","metadata":{"id":"f3fba2f8"}},{"cell_type":"code","source":"lookup_table = {\n    (1, 0): 0,\n    (1, -1): 1,\n    (0, -1): 2,\n    (-1, -1): 3,\n    (-1, 0): 4,\n    (-1, 1): 5,\n    (0, 1): 6,\n    (1, 1): 7\n}","metadata":{"id":"0f2b7168","execution":{"iopub.status.busy":"2024-03-10T19:30:26.058464Z","iopub.execute_input":"2024-03-10T19:30:26.059203Z","iopub.status.idle":"2024-03-10T19:30:26.065708Z","shell.execute_reply.started":"2024-03-10T19:30:26.059159Z","shell.execute_reply":"2024-03-10T19:30:26.064641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can generate a histogram of chain codes by counting how many times each value appears in the chain code. The next cell will loop through points of the best contour to print the chain code and calculate the histogram.\n- First, we initialize the histogram `hist` to zeros. The histogram has 8 values that represent the number of occurrences of each chain code value (from 0 to 7)\n- After that, we loop through the points of the best contour (except the last point)\n- Inside the loop, we store the current point (index `i`) in `pt1` and the next point (index `i+1`) in `pt2`\n- We calculate `dx` and `dy` by subtracting the x and y values between `pt2` and `pt1`\n- We give (`dx`, `dy`) to the lookup table to obtain the chain code value (we can print it if we want)\n- We increment the histogram at the index of the chain code value `hist[code] += 1`\n\nOutside the loop, we normalize the histogram by dividing it by the total sum: `hist/hist.sum()`. The normalized histogram will remain the same even if the object's size increases","metadata":{"id":"e6158db5"}},{"cell_type":"code","source":"import numpy as np\n\nhist = np.zeros((8,))","metadata":{"id":"39101399","execution":{"iopub.status.busy":"2024-03-10T19:30:31.850249Z","iopub.execute_input":"2024-03-10T19:30:31.850659Z","iopub.status.idle":"2024-03-10T19:30:31.855842Z","shell.execute_reply.started":"2024-03-10T19:30:31.850628Z","shell.execute_reply":"2024-03-10T19:30:31.85472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist.shape","metadata":{"id":"db374542","execution":{"iopub.status.busy":"2024-03-10T19:30:36.718464Z","iopub.execute_input":"2024-03-10T19:30:36.719012Z","iopub.status.idle":"2024-03-10T19:30:36.726182Z","shell.execute_reply.started":"2024-03-10T19:30:36.718975Z","shell.execute_reply":"2024-03-10T19:30:36.72485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nhist = np.zeros((8,))\n\nfor i in range(len(best_contour)-1):\n    (x1, y1) = best_contour[i][0]\n    (x2, y2) = best_contour[i+1][0]\n    dx = x2 - x1\n    dy = y2 - y1\n    code = lookup_table[(dx, dy)]\n    print(code, end='')\n    hist[code] += 1\n\nprint(\"\\n\")\nprint(hist/hist.sum())","metadata":{"id":"c1e31dc3","execution":{"iopub.status.busy":"2024-03-10T19:30:42.248515Z","iopub.execute_input":"2024-03-10T19:30:42.248908Z","iopub.status.idle":"2024-03-10T19:30:42.263535Z","shell.execute_reply.started":"2024-03-10T19:30:42.24887Z","shell.execute_reply":"2024-03-10T19:30:42.262682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We wrap what we did so far in a function that takes an RGB image `img_rgb` and returns the normalized histogram of chain codes. We can use this histogram as a feature descriptor for the image","metadata":{"id":"726bf11d"}},{"cell_type":"code","source":"def chain_hist(img_rgb):\n\n    best_contour = find_best_contour(img_rgb)\n\n    lookup_table = {\n        (1, 0): 0,\n        (1, -1): 1,\n        (0, -1): 2,\n        (-1, -1): 3,\n        (-1, 0): 4,\n        (-1, 1): 5,\n        (0, 1): 6,\n        (1, 1): 7\n    }\n\n    hist = np.zeros((8,))\n    for i in range(len(best_contour)-1):\n        pt1 = best_contour[i][0]\n        pt2 = best_contour[i+1][0]\n        dx = pt2[0] - pt1[0]\n        dy = pt2[1] - pt1[1]\n        code = lookup_table[(dx, dy)]\n        hist[code] += 1\n\n    return hist/hist.sum()","metadata":{"id":"6fdbcc4b","execution":{"iopub.status.busy":"2024-03-10T19:30:46.881415Z","iopub.execute_input":"2024-03-10T19:30:46.882541Z","iopub.status.idle":"2024-03-10T19:30:46.891552Z","shell.execute_reply.started":"2024-03-10T19:30:46.882496Z","shell.execute_reply":"2024-03-10T19:30:46.890632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(chain_hist(img))","metadata":{"id":"ec881685","execution":{"iopub.status.busy":"2024-03-10T19:30:51.389884Z","iopub.execute_input":"2024-03-10T19:30:51.390456Z","iopub.status.idle":"2024-03-10T19:30:51.398866Z","shell.execute_reply.started":"2024-03-10T19:30:51.390427Z","shell.execute_reply":"2024-03-10T19:30:51.397688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Support Vector Machine for shape classification\nWe use the normalized histograms of chain codes as features to train a Support Vector machine (SVM) classifier to classify the images of shapes (circle, square, star, rectangle)\n\nWe use the Four shapes dataset from kaggle [dataset link](https://www.kaggle.com/datasets/smeschke/four-shapes)\n\nThe next function takes the path to the data folder (`data_path`) and returns a DataFrame with two columns: image path, and output\n\n## Creating a DataFrame for our dataset","metadata":{"id":"a3ca14d0"}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ndef create_df(data_path):\n\n    # the class_dict is a mapping between class name and value\n    class_dict = {\n        'circle': 0,\n        'square': 1,\n        'star': 2,\n        'triangle': 3\n    }\n\n    # we store image paths and outputs here\n    df = []\n\n    # for each class\n    for class_name, class_value in class_dict.items():\n        class_folder = os.path.join(data_path, class_name)\n        # for each image in class folder\n        for f in os.listdir(class_folder):\n            f_path = os.path.join(class_folder, f)\n            # if this is a \"png\" file, add its path and output\n            if f_path.lower().endswith('.png'):\n                df.append([f_path, class_value])\n\n    # create a dataframe of image paths and outputs\n    df = pd.DataFrame(df, columns=['path', 'output'])\n\n    return df","metadata":{"id":"51a95e1a","execution":{"iopub.status.busy":"2024-03-10T19:31:07.459162Z","iopub.execute_input":"2024-03-10T19:31:07.462112Z","iopub.status.idle":"2024-03-10T19:31:07.470901Z","shell.execute_reply.started":"2024-03-10T19:31:07.462066Z","shell.execute_reply":"2024-03-10T19:31:07.469089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use the previous function to read the data from the `shapes_dataset/` folder","metadata":{"id":"b790a9e3"}},{"cell_type":"code","source":"data = create_df('/kaggle/input/four-shapes/shapes')\ndata","metadata":{"id":"32cbc63d","execution":{"iopub.status.busy":"2024-03-10T19:32:19.941568Z","iopub.execute_input":"2024-03-10T19:32:19.941993Z","iopub.status.idle":"2024-03-10T19:32:20.646356Z","shell.execute_reply.started":"2024-03-10T19:32:19.941966Z","shell.execute_reply":"2024-03-10T19:32:20.645362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting features","metadata":{"id":"dd1e1996"}},{"cell_type":"markdown","source":"We loop through image paths to read each image and extract features from it using our `chain_hist` function. We store all images' features in an array `X` and return it","metadata":{"id":"afb2aa62"}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef extract_features(img_paths):\n    n = len(img_paths)\n    X = np.zeros((n, 8))\n    for i in tqdm(range(n)):\n        f_path = img_paths[i]\n        img = imread(f_path)\n        features = chain_hist(img)\n        X[i] = features\n    return X","metadata":{"id":"52f0c80b","execution":{"iopub.status.busy":"2024-03-10T19:32:33.19837Z","iopub.execute_input":"2024-03-10T19:32:33.199461Z","iopub.status.idle":"2024-03-10T19:32:33.204655Z","shell.execute_reply.started":"2024-03-10T19:32:33.199426Z","shell.execute_reply":"2024-03-10T19:32:33.203974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = extract_features(data['path'])","metadata":{"id":"a2540740","execution":{"iopub.status.busy":"2024-03-10T19:32:35.507955Z","iopub.execute_input":"2024-03-10T19:32:35.508359Z","iopub.status.idle":"2024-03-10T19:34:26.255875Z","shell.execute_reply.started":"2024-03-10T19:32:35.508327Z","shell.execute_reply":"2024-03-10T19:34:26.254908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We store outputs in `y`","metadata":{"id":"1d3be121"}},{"cell_type":"code","source":"y = data['output']","metadata":{"id":"613ef29e","execution":{"iopub.status.busy":"2024-03-10T19:35:01.723959Z","iopub.execute_input":"2024-03-10T19:35:01.72434Z","iopub.status.idle":"2024-03-10T19:35:01.729944Z","shell.execute_reply.started":"2024-03-10T19:35:01.724313Z","shell.execute_reply":"2024-03-10T19:35:01.728888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting dataset","metadata":{"id":"a5ed8cb3"}},{"cell_type":"markdown","source":"We split the data to train and test sets","metadata":{"id":"677300a9"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=0\n)","metadata":{"id":"8f0e75da","execution":{"iopub.status.busy":"2024-03-10T19:35:06.384808Z","iopub.execute_input":"2024-03-10T19:35:06.385199Z","iopub.status.idle":"2024-03-10T19:35:07.148357Z","shell.execute_reply.started":"2024-03-10T19:35:06.385171Z","shell.execute_reply":"2024-03-10T19:35:07.147121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"9b566ead"}},{"cell_type":"markdown","source":"We train our Support vector machine","metadata":{"id":"d8ca772f"}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"id":"ef17b537","execution":{"iopub.status.busy":"2024-03-10T19:35:16.995875Z","iopub.execute_input":"2024-03-10T19:35:16.996875Z","iopub.status.idle":"2024-03-10T19:35:17.078678Z","shell.execute_reply.started":"2024-03-10T19:35:16.996845Z","shell.execute_reply":"2024-03-10T19:35:17.077654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SVC()\nmodel.fit(X_train, y_train)","metadata":{"id":"b1c8a01e","execution":{"iopub.status.busy":"2024-03-10T19:35:21.384027Z","iopub.execute_input":"2024-03-10T19:35:21.384429Z","iopub.status.idle":"2024-03-10T19:35:22.377075Z","shell.execute_reply.started":"2024-03-10T19:35:21.384401Z","shell.execute_reply":"2024-03-10T19:35:22.375951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculating accuracy","metadata":{"id":"64db89c8"}},{"cell_type":"markdown","source":"We print the accuracy of train and test","metadata":{"id":"74e7e086"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\nprint(accuracy_score(y_train, y_pred_train))\nprint(accuracy_score(y_test, y_pred_test))","metadata":{"id":"2bdb8f4d","execution":{"iopub.status.busy":"2024-03-10T19:35:26.20437Z","iopub.execute_input":"2024-03-10T19:35:26.204812Z","iopub.status.idle":"2024-03-10T19:35:28.450665Z","shell.execute_reply.started":"2024-03-10T19:35:26.204779Z","shell.execute_reply":"2024-03-10T19:35:28.449475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing with images outside the dataset","metadata":{"id":"56b6ea4b"}},{"cell_type":"markdown","source":"We test the model with images outside the dataset","metadata":{"id":"60075b6a"}},{"cell_type":"code","source":"def test_model(model, img_path):\n    classes = ['circle', 'square', 'star', 'triangle']\n    img = imread(img_path)\n    x = chain_hist(img)\n    c = model.predict([x])[0]\n    print(img_path, '->', classes[c])","metadata":{"id":"5e54f2fb","execution":{"iopub.status.busy":"2024-03-10T19:35:36.511092Z","iopub.execute_input":"2024-03-10T19:35:36.511497Z","iopub.status.idle":"2024-03-10T19:35:36.51825Z","shell.execute_reply.started":"2024-03-10T19:35:36.511467Z","shell.execute_reply":"2024-03-10T19:35:36.517055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(model, '/kaggle/input/imagesss/Square.png')\ntest_model(model, '/kaggle/input/imagesss/star.png')\ntest_model(model, '/kaggle/input/imagesss/circle.png')\ntest_model(model, '/kaggle/input/imagesss/triangle.png')\ntest_model(model, '/kaggle/input/imagesss/square-hollow.png')\ntest_model(model, '/kaggle/input/imagesss/star-hollow.png')\ntest_model(model, '/kaggle/input/imagesss/circle-hollow.png')\ntest_model(model, '/kaggle/input/imagesss/triangle-hollow.png')","metadata":{"id":"67a65b87","execution":{"iopub.status.busy":"2024-03-10T19:53:52.747508Z","iopub.execute_input":"2024-03-10T19:53:52.747967Z","iopub.status.idle":"2024-03-10T19:53:52.806956Z","shell.execute_reply.started":"2024-03-10T19:53:52.747936Z","shell.execute_reply":"2024-03-10T19:53:52.805999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the model is correct for all images except the circle.\n\nThis problem can be solved by using a better dataset for training (The contour of the circles in the dataset are not smooth like the circles outside the dataset).\n\nOr we can use a better feature descriptor for the images instead of the histogram of chain codes.","metadata":{"id":"f7124926"}},{"cell_type":"markdown","source":"# Object detection example","metadata":{"id":"d1f2d36c"}},{"cell_type":"code","source":"img = imread('/kaggle/input/imagesss/shapes.png')\nimshow(img)","metadata":{"scrolled":true,"id":"58f4af93","execution":{"iopub.status.busy":"2024-03-10T19:46:46.363848Z","iopub.execute_input":"2024-03-10T19:46:46.364263Z","iopub.status.idle":"2024-03-10T19:46:46.6606Z","shell.execute_reply.started":"2024-03-10T19:46:46.364232Z","shell.execute_reply":"2024-03-10T19:46:46.659511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_model(model, img_path):\n    classes = ['circle', 'square', 'star', 'triangle']\n    img = imread(img_path)\n    img_copy = img.copy()  # Create a copy to draw on\n    img_rgb = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)  # Convert to RGB for consistency\n    \n    # Find contours\n    contours, _ = cv2.findContours(rgb2bin(img_rgb), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    for contour in contours:\n        # Calculate bounding rectangle\n        x, y, w, h = cv2.boundingRect(contour)\n        # bounding rectangle\n        cv2.rectangle(img_copy, (x, y), (x + w, y + h), (255, 0, 0), 2)\n        \n        # Get the centroid of the bounding rectangle\n        centroid_x = x + w //10\n        centroid_y = y + h // 100\n        \n        # Get the predicted class\n        x = chain_hist(img[y:y+h, x:x+w])  # Extract features from the bounding box region\n        c = model.predict([x])[0]\n        class_name = classes[c]\n        \n        # Write class name on top of the bounding box\n        cv2.putText(img_copy, class_name, (centroid_x, centroid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n    \n    # Display the image with bounding boxes and labels\n    imshow(img_copy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:54:08.593599Z","iopub.execute_input":"2024-03-10T20:54:08.594479Z","iopub.status.idle":"2024-03-10T20:54:08.60468Z","shell.execute_reply.started":"2024-03-10T20:54:08.594443Z","shell.execute_reply":"2024-03-10T20:54:08.603696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have already defined the `test_model` function\n\n# Provide the file path of the image you want to test\nimage_path = \"/kaggle/input/imagesss/shapes.png\"\n\n# Call the test_model function with the image path\ntest_model(model, image_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:54:09.209602Z","iopub.execute_input":"2024-03-10T20:54:09.210002Z","iopub.status.idle":"2024-03-10T20:54:09.546799Z","shell.execute_reply.started":"2024-03-10T20:54:09.209973Z","shell.execute_reply":"2024-03-10T20:54:09.545829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try to write a program to take the previous image as input and produce the following output:\n\n<img src=\"images/shapes-result-example.png\" width=\"400\" align=\"left\">","metadata":{"id":"d3ef643d"}},{"cell_type":"markdown","source":"# Other feature descriptors\nThe method we used is very simple and won't work for complex objects (such as cats). If we want to deal with complex objects, we should use a better feature descriptor. Examples include:\n- SIFT (Scale-Invariant Feature Transform)\n- SURF (Speeded-Up Robust Features)\n- LBP (Local Binary Patterns)\n- HOG (Histogram Oriented Gradients)\n- Deep-learning based:\n  - Auto encoders\n  - Pre-trained models such as ResNet, etc.","metadata":{"id":"880b02dd"}}]}